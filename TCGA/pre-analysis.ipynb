{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Analysis Stuff\n",
    "\n",
    "\n",
    "## General Information\n",
    "\n",
    "Baseline includes 1,090 (a random number more than 1000) cases taken from the Orignal Manifesto. The cases were downloaded using the gdc client. Notice how the base line has an executable file called gdc clinet => it is `./gdc-client download -m updated.txt `\n",
    "\n",
    "I used all the AML cases here since for V617F, 2 out of 4 cases were from AML, 1 from BetaAML and one was from liver. \n",
    "\n",
    "Also for all the Jak2 Mutationas, AML was the most common!\n",
    "\n",
    "\n",
    "## How the files are structured\n",
    "\n",
    "The files are structured as follows\n",
    "\n",
    "1. **Baseline** includes 1090 AML cases that we use to form a baseline values for all the gene expression levels\n",
    "\n",
    "2. **Deleterious** includes 32 cases that have a **high** Polyphen scored mutation in Jak2 - all of them are missense mutations. \n",
    "\n",
    "    a. The mutations are structured as follows - ![Image of all the deleterious mutations](polyphen.png)\n",
    "\n",
    "    Here we use everything that has an impact of PR. Data collected from here - https://portal.gdc.cancer.gov/genes/ENSG00000096968\n",
    "\n",
    "3. **V617F** includes all the cases that have the V617f mutations\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Already used it no need to use this code again!\n",
    "\n",
    "# import pandas as pd\n",
    "# import random\n",
    "\n",
    "# # Load the manifest file\n",
    "# file_path = 'GDC Manifest Aug 22.txt'\n",
    "\n",
    "# # Read the file into a DataFrame\n",
    "# df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# # Randomly select 1000 rows\n",
    "# df_sampled = df.sample(n=1090, random_state=420)\n",
    "\n",
    "# # Save the sampled DataFrame to a new file\n",
    "# output_path = 'manifest.txt'\n",
    "# df_sampled.to_csv(output_path, sep='\\t', index=False)\n",
    "\n",
    "# output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Define paths\n",
    "# tcga_folder = 'TCGA'\n",
    "# baseline_folder = os.path.join(tcga_folder, 'baseline')\n",
    "# data_folder = os.path.join(baseline_folder, 'data')\n",
    "\n",
    "# # Create the data folder if it doesn't exist\n",
    "# os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# # Determine the starting file_counter based on existing files in data folder\n",
    "# existing_files = [f for f in os.listdir(data_folder) if f.endswith('.tsv')]\n",
    "# if existing_files:\n",
    "#     existing_numbers = [int(os.path.splitext(f)[0]) for f in existing_files]\n",
    "#     file_counter = max(existing_numbers) + 1\n",
    "# else:\n",
    "#     file_counter = 1\n",
    "\n",
    "# # Function to clean up folders, move files, and delete empty folders\n",
    "# def clean_and_reorganize_folders(baseline_folder, data_folder):\n",
    "#     global file_counter\n",
    "#     for case_folder in os.listdir(baseline_folder):\n",
    "#         case_path = os.path.join(baseline_folder, case_folder)\n",
    "        \n",
    "#         # Skip non-directory files like .DS_Store\n",
    "#         if not os.path.isdir(case_path):\n",
    "#             continue\n",
    "        \n",
    "#         log_folder = os.path.join(case_path, 'logs')\n",
    "        \n",
    "#         # Remove the logs directory and its contents recursively\n",
    "#         if os.path.exists(log_folder):\n",
    "#             shutil.rmtree(log_folder)\n",
    "        \n",
    "#         # Move the .tsv file to the data folder and rename it\n",
    "#         for file_name in os.listdir(case_path):\n",
    "#             if file_name.endswith('.tsv'):\n",
    "#                 src_file_path = os.path.join(case_path, file_name)\n",
    "#                 dest_file_path = os.path.join(data_folder, f\"{file_counter}.tsv\")\n",
    "#                 shutil.move(src_file_path, dest_file_path)\n",
    "#                 file_counter += 1\n",
    "        \n",
    "#         # Remove the now-empty case folder\n",
    "#         if not os.listdir(case_path):  # Check if the directory is empty\n",
    "#             os.rmdir(case_path)\n",
    "\n",
    "# # Clean and reorganize baseline folders\n",
    "# clean_and_reorganize_folders(baseline_folder, data_folder)\n",
    "\n",
    "# print(f\"Data files have been moved to '{data_folder}' and renamed sequentially. Empty folders have been deleted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Define the path to the data folder\n",
    "# data_folder = os.path.join('TCGA', 'baseline', 'data')\n",
    "\n",
    "# # Get a list of all .tsv files in the data folder\n",
    "# files = [f for f in os.listdir(data_folder) if f.endswith('.tsv')]\n",
    "\n",
    "# # Sort the files to ensure consistent renaming\n",
    "# files.sort()\n",
    "\n",
    "# # Rename each file sequentially from 1.tsv onwards\n",
    "# for i, file_name in enumerate(files, start=1):\n",
    "#     old_file_path = os.path.join(data_folder, file_name)\n",
    "#     new_file_name = f\"{i}.tsv\"\n",
    "#     new_file_path = os.path.join(data_folder, new_file_name)\n",
    "#     os.rename(old_file_path, new_file_path)\n",
    "\n",
    "# print(f\"Renamed {len(files)} files sequentially from 1.tsv to {len(files)}.tsv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Define the paths\n",
    "# tcga_folder = 'TCGA'\n",
    "# baseline_folder = os.path.join(tcga_folder, 'baseline')\n",
    "# data_folder = os.path.join(baseline_folder, 'data')\n",
    "\n",
    "# # Function to clean up all folders in TCGA except for the 'data' folder\n",
    "# def clean_tcga_folder(tcga_folder, data_folder):\n",
    "#     for root, dirs, files in os.walk(baseline_folder, topdown=False):\n",
    "#         for name in dirs:\n",
    "#             folder_path = os.path.join(root, name)\n",
    "#             if folder_path != data_folder:\n",
    "#                 shutil.rmtree(folder_path)\n",
    "#                 print(f\"Deleted folder: {folder_path}\")\n",
    "\n",
    "# # Clean up the folders\n",
    "# clean_tcga_folder(tcga_folder, data_folder)\n",
    "\n",
    "# print(f\"Cleaned up all folders in '{tcga_folder}' except for the 'data' folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1036/1036 [00:41<00:00, 24.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed baseline data saved to 'TCGA/baseline/trimmed_baseline_data.tsv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_folder = os.path.join('TCGA', 'baseline', 'data')\n",
    "output_trimmed_baseline_file = os.path.join('TCGA', 'baseline', 'trimmed_baseline_data.tsv')\n",
    "\n",
    "# Initialize lists to hold the gene IDs and expression data\n",
    "gene_ids = []\n",
    "gene_names = []\n",
    "gene_types = []\n",
    "expression_data = None\n",
    "\n",
    "# Get the list of all .tsv files\n",
    "tsv_files = sorted([f for f in os.listdir(data_folder) if f.endswith('.tsv')])\n",
    "\n",
    "# Iterate through all the TSV files and collect data\n",
    "for i, file_name in enumerate(tqdm(tsv_files, desc=\"Processing files\")):\n",
    "    file_path = os.path.join(data_folder, file_name)\n",
    "    df = pd.read_csv(file_path, sep='\\t', comment='#')\n",
    "    \n",
    "    if i == 0:\n",
    "        gene_ids = df['gene_id'].values\n",
    "        gene_names = df['gene_name'].values\n",
    "        gene_types = df['gene_type'].values\n",
    "        expression_data = np.zeros((len(gene_ids), len(tsv_files)), dtype=np.float32)\n",
    "    \n",
    "    # Use numpy array operations to fill in the data matrix\n",
    "    expression_data[:, i] = df['tpm_unstranded'].values  # Use tpm_unstranded instead of unstranded\n",
    "\n",
    "# Calculate the trimmed mean across all cases\n",
    "trimmed_mean_expression = np.zeros(len(gene_ids), dtype=np.float32)\n",
    "\n",
    "for j in range(expression_data.shape[0]):\n",
    "    # Sort the values for the gene and trim the top and bottom 1%\n",
    "    sorted_values = np.sort(expression_data[j, :])\n",
    "    trimmed_values = sorted_values[int(0.01 * len(sorted_values)) : int(0.99 * len(sorted_values))]\n",
    "    trimmed_mean_expression[j] = np.mean(trimmed_values)\n",
    "\n",
    "# Calculate the median across all cases (unchanged)\n",
    "median_expression = np.median(expression_data, axis=1)\n",
    "\n",
    "# Create a new DataFrame to hold the trimmed baseline data\n",
    "trimmed_baseline_df = pd.DataFrame({\n",
    "    'gene_id': gene_ids,\n",
    "    'gene_name': gene_names,\n",
    "    'gene_type': gene_types,\n",
    "    'trimmed_mean_expression': trimmed_mean_expression,\n",
    "    'median_expression': median_expression\n",
    "})\n",
    "\n",
    "# Save the trimmed baseline data to a new TSV file\n",
    "trimmed_baseline_df.to_csv(output_trimmed_baseline_file, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Trimmed baseline data saved to '{output_trimmed_baseline_file}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now we will do something quite similar to that for all the deleterious and V617F folders but with a few changes.\n",
    "\n",
    "**First we clean the data and organize all the cases.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 32 files sequentially from d1.tsv to d32.tsv in TCGA/Deleterious\n",
      "Renamed 4 files sequentially from v1.tsv to v4.tsv in TCGA/V617F\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "tcga_folder = 'TCGA'\n",
    "deleterious_folder = os.path.join(tcga_folder, 'Deleterious')\n",
    "v617f_folder = os.path.join(tcga_folder, 'V617F')\n",
    "\n",
    "# Rename and Move Files\n",
    "\n",
    "def rename_files(folder, prefix):\n",
    "    file_counter = 1\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.tsv'):\n",
    "                old_file_path = os.path.join(root, file_name)\n",
    "                new_file_name = f\"{prefix}{file_counter}.tsv\"\n",
    "                new_file_path = os.path.join(folder, new_file_name)\n",
    "                os.rename(old_file_path, new_file_path)\n",
    "                file_counter += 1\n",
    "\n",
    "    print(f\"Renamed {file_counter-1} files sequentially from {prefix}1.tsv to {prefix}{file_counter-1}.tsv in {folder}\")\n",
    "\n",
    "# Rename files in Deleterious and V617F folders\n",
    "rename_files(deleterious_folder, 'd')\n",
    "rename_files(v617f_folder, 'v')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will use this data to create a deleterious tsv file and a v617f tsv file where the only data recorded will be the tpm unstranded data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing deleterious.tsv: 100%|██████████| 32/32 [00:01<00:00, 27.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleterious.tsv created in TCGA/Deleterious\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing v617f.tsv: 100%|██████████| 4/4 [00:00<00:00, 26.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v617f.tsv created in TCGA/V617F\n"
     ]
    }
   ],
   "source": [
    "# Define the function to create the combined TSV file\n",
    "def create_combined_tpm_file(folder, output_file_name):\n",
    "    data_folder = os.path.join(folder, 'data')\n",
    "    output_file_path = os.path.join(folder, output_file_name)\n",
    "\n",
    "    # Get the list of all .tsv files\n",
    "    tsv_files = sorted([f for f in os.listdir(data_folder) if f.endswith('.tsv')])\n",
    "\n",
    "    # Initialize variables\n",
    "    combined_data = None\n",
    "    gene_ids = None\n",
    "\n",
    "    # Process each file and combine the TPM unstranded data\n",
    "    for file_name in tqdm(tsv_files, desc=f\"Processing {output_file_name}\"):\n",
    "        file_path = os.path.join(data_folder, file_name)\n",
    "        df = pd.read_csv(file_path, sep='\\t', comment='#')\n",
    "\n",
    "        if combined_data is None:\n",
    "            # Initialize the combined DataFrame with gene IDs and the first file's TPM data\n",
    "            gene_ids = df['gene_id'].values\n",
    "            combined_data = pd.DataFrame(index=gene_ids)\n",
    "        \n",
    "        # Add the TPM unstranded data for this case\n",
    "        combined_data[file_name] = df['tpm_unstranded'].values\n",
    "\n",
    "    # Calculate the average TPM unstranded value across all cases\n",
    "    combined_data['average'] = combined_data.mean(axis=1)\n",
    "\n",
    "    # Add the gene information back to the DataFrame\n",
    "    combined_data.insert(0, 'gene_id', gene_ids)\n",
    "    combined_data.insert(1, 'gene_name', df['gene_name'].values)\n",
    "    combined_data.insert(2, 'gene_type', df['gene_type'].values)\n",
    "\n",
    "    # Save the combined data to a new TSV file\n",
    "    combined_data.to_csv(output_file_path, sep='\\t', index=False)\n",
    "\n",
    "    print(f\"{output_file_name} created in {folder}\")\n",
    "\n",
    "# Create combined files for Deleterious and V617F folders\n",
    "create_combined_tpm_file(os.path.join('TCGA', 'Deleterious'), 'deleterious.tsv')\n",
    "create_combined_tpm_file(os.path.join('TCGA', 'V617F'), 'v617f.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file: TCGA/Deleterious/deleterious.tsv\n",
      "Cleaned file: TCGA/V617F/v617f.tsv\n",
      "Cleaned file: TCGA/baseline/trimmed_baseline_data.tsv\n"
     ]
    }
   ],
   "source": [
    "# # Function to remove specific rows from a TSV file\n",
    "# def clean_tsv_file(file_path):\n",
    "#     # Read the TSV file\n",
    "#     df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "#     # Remove rows 2 to 5 (indices 1 to 4 in 0-based indexing)\n",
    "#     df_cleaned = df.drop(index=[1, 2, 3, 4])\n",
    "\n",
    "#     # Save the cleaned DataFrame back to the same file\n",
    "#     df_cleaned.to_csv(file_path, sep='\\t', index=False)\n",
    "\n",
    "#     print(f\"Cleaned file: {file_path}\")\n",
    "\n",
    "# # Define the paths to the files\n",
    "# deleterious_file = os.path.join('TCGA', 'Deleterious', 'deleterious.tsv')\n",
    "# v617f_file = os.path.join('TCGA', 'V617F', 'v617f.tsv')\n",
    "# trimmed_baseline_file = os.path.join('TCGA', 'baseline', 'trimmed_baseline_data.tsv')\n",
    "\n",
    "# # Clean all three files\n",
    "# clean_tsv_file(deleterious_file)\n",
    "# clean_tsv_file(v617f_file)\n",
    "# clean_tsv_file(trimmed_baseline_file)\n",
    "\n",
    "print(\"hi there - if this runs hopefully the above code did not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New file with gene_id and mean expression saved as 'TCGA/baseline/gene_mean_expression.tsv'\n",
      "Removed columns from 'TCGA/V617F/v617f.tsv'\n",
      "Removed columns from 'TCGA/Deleterious/deleterious.tsv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Task 1: Create a new file with just gene_id and trimmed_mean_expression from trimmed_baseline_data.tsv\n",
    "\n",
    "# Define the path for trimmed baseline data\n",
    "trimmed_baseline_file = os.path.join('TCGA', 'baseline', 'trimmed_baseline_data.tsv')\n",
    "new_trimmed_baseline_file = os.path.join('TCGA', 'baseline', 'gene_mean_expression.tsv')\n",
    "\n",
    "# Load the trimmed baseline data\n",
    "trimmed_baseline_df = pd.read_csv(trimmed_baseline_file, sep='\\t')\n",
    "\n",
    "# Create a new DataFrame with only gene_id and trimmed_mean_expression\n",
    "new_trimmed_baseline_df = trimmed_baseline_df[['gene_id', 'trimmed_mean_expression']]\n",
    "\n",
    "# Save the new DataFrame to a new file\n",
    "new_trimmed_baseline_df.to_csv(new_trimmed_baseline_file, sep='\\t', index=False)\n",
    "\n",
    "print(f\"New file with gene_id and mean expression saved as '{new_trimmed_baseline_file}'\")\n",
    "\n",
    "# Task 2: Remove gene_name and gene_type columns from v617f.tsv and deleterious.tsv\n",
    "\n",
    "def remove_columns(file_path, columns_to_remove):\n",
    "    # Load the TSV file\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "    # Remove the specified columns\n",
    "    df = df.drop(columns=columns_to_remove)\n",
    "\n",
    "    # Save the updated DataFrame back to the same file\n",
    "    df.to_csv(file_path, sep='\\t', index=False)\n",
    "\n",
    "    print(f\"Removed columns from '{file_path}'\")\n",
    "\n",
    "# Define the paths for v617f.tsv and deleterious.tsv\n",
    "v617f_file = os.path.join('TCGA', 'V617F', 'v617f.tsv')\n",
    "deleterious_file = os.path.join('TCGA', 'Deleterious', 'deleterious.tsv')\n",
    "\n",
    "# Columns to remove\n",
    "columns_to_remove = ['gene_name', 'gene_type']\n",
    "\n",
    "# Remove columns from v617f.tsv and deleterious.tsv\n",
    "remove_columns(v617f_file, columns_to_remove)\n",
    "remove_columns(deleterious_file, columns_to_remove)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What this did\n",
    "\n",
    "Okay so now we have gene mean expressions.tsv file which has the mean tsv for all the AML cases. We also have deletrious.tsv which has the values and the average expression profiles for all the deleterious genes based on their polyphen score - we have a total of 32 files here and finally we have v617f.tsv file which has all the data for the v617f positive cell lines which are about 4. \n",
    "\n",
    "Now we will proceed to analysis. This is what we will do for analysis-\n",
    "\n",
    "We want to identify the most differentially expressed genes when there is a deleterious mutation or v617f mutation in the Jak2 gene and we have the data for that as mentioned above. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
