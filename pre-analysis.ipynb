{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Analysis Stuff\n",
    "\n",
    "\n",
    "## General Information\n",
    "\n",
    "Baseline includes 1,090 (a random number more than 1000) cases taken from the Orignal Manifesto. The cases were downloaded using the gdc client. Notice how the base line has an executable file called gdc clinet => it is `./gdc-client download -m updated.txt `\n",
    "\n",
    "I used all the AML cases here since for V617F, 2 out of 4 cases were from AML, 1 from BetaAML and one was from liver. \n",
    "\n",
    "Also for all the Jak2 Mutationas, AML was the most common!\n",
    "\n",
    "\n",
    "## How the files are structured\n",
    "\n",
    "The files are structured as follows\n",
    "\n",
    "1. **Baseline** includes 1090 AML cases that we use to form a baseline values for all the gene expression levels\n",
    "\n",
    "2. **Deleterious** includes 32 cases that have a **high** Polyphen scored mutation in Jak2 - all of them are missense mutations. \n",
    "\n",
    "    a. The mutations are structured as follows - ![Image of all the deleterious mutations](polyphen.png)\n",
    "\n",
    "    Here we use everything that has an impact of PR. Data collected from here - https://portal.gdc.cancer.gov/genes/ENSG00000096968\n",
    "\n",
    "3. **V617F** includes all the cases that have the V617f mutations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## The Pre-Analysis work\n",
    "\n",
    "The files are structured such that each folder has folders for all the case and than each case folder has a tab seperated value aka .tsv file that has data. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Already used it no need to use this code again!\n",
    "\n",
    "# import pandas as pd\n",
    "# import random\n",
    "\n",
    "# # Load the manifest file\n",
    "# file_path = 'GDC Manifest Aug 22.txt'\n",
    "\n",
    "# # Read the file into a DataFrame\n",
    "# df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# # Randomly select 1000 rows\n",
    "# df_sampled = df.sample(n=1090, random_state=420)\n",
    "\n",
    "# # Save the sampled DataFrame to a new file\n",
    "# output_path = 'manifest.txt'\n",
    "# df_sampled.to_csv(output_path, sep='\\t', index=False)\n",
    "\n",
    "# output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Define paths\n",
    "# tcga_folder = 'TCGA'\n",
    "# baseline_folder = os.path.join(tcga_folder, 'baseline')\n",
    "# data_folder = os.path.join(baseline_folder, 'data')\n",
    "\n",
    "# # Create the data folder if it doesn't exist\n",
    "# os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# # Determine the starting file_counter based on existing files in data folder\n",
    "# existing_files = [f for f in os.listdir(data_folder) if f.endswith('.tsv')]\n",
    "# if existing_files:\n",
    "#     existing_numbers = [int(os.path.splitext(f)[0]) for f in existing_files]\n",
    "#     file_counter = max(existing_numbers) + 1\n",
    "# else:\n",
    "#     file_counter = 1\n",
    "\n",
    "# # Function to clean up folders, move files, and delete empty folders\n",
    "# def clean_and_reorganize_folders(baseline_folder, data_folder):\n",
    "#     global file_counter\n",
    "#     for case_folder in os.listdir(baseline_folder):\n",
    "#         case_path = os.path.join(baseline_folder, case_folder)\n",
    "        \n",
    "#         # Skip non-directory files like .DS_Store\n",
    "#         if not os.path.isdir(case_path):\n",
    "#             continue\n",
    "        \n",
    "#         log_folder = os.path.join(case_path, 'logs')\n",
    "        \n",
    "#         # Remove the logs directory and its contents recursively\n",
    "#         if os.path.exists(log_folder):\n",
    "#             shutil.rmtree(log_folder)\n",
    "        \n",
    "#         # Move the .tsv file to the data folder and rename it\n",
    "#         for file_name in os.listdir(case_path):\n",
    "#             if file_name.endswith('.tsv'):\n",
    "#                 src_file_path = os.path.join(case_path, file_name)\n",
    "#                 dest_file_path = os.path.join(data_folder, f\"{file_counter}.tsv\")\n",
    "#                 shutil.move(src_file_path, dest_file_path)\n",
    "#                 file_counter += 1\n",
    "        \n",
    "#         # Remove the now-empty case folder\n",
    "#         if not os.listdir(case_path):  # Check if the directory is empty\n",
    "#             os.rmdir(case_path)\n",
    "\n",
    "# # Clean and reorganize baseline folders\n",
    "# clean_and_reorganize_folders(baseline_folder, data_folder)\n",
    "\n",
    "# print(f\"Data files have been moved to '{data_folder}' and renamed sequentially. Empty folders have been deleted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Define the path to the data folder\n",
    "# data_folder = os.path.join('TCGA', 'baseline', 'data')\n",
    "\n",
    "# # Get a list of all .tsv files in the data folder\n",
    "# files = [f for f in os.listdir(data_folder) if f.endswith('.tsv')]\n",
    "\n",
    "# # Sort the files to ensure consistent renaming\n",
    "# files.sort()\n",
    "\n",
    "# # Rename each file sequentially from 1.tsv onwards\n",
    "# for i, file_name in enumerate(files, start=1):\n",
    "#     old_file_path = os.path.join(data_folder, file_name)\n",
    "#     new_file_name = f\"{i}.tsv\"\n",
    "#     new_file_path = os.path.join(data_folder, new_file_name)\n",
    "#     os.rename(old_file_path, new_file_path)\n",
    "\n",
    "# print(f\"Renamed {len(files)} files sequentially from 1.tsv to {len(files)}.tsv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Define the paths\n",
    "# tcga_folder = 'TCGA'\n",
    "# baseline_folder = os.path.join(tcga_folder, 'baseline')\n",
    "# data_folder = os.path.join(baseline_folder, 'data')\n",
    "\n",
    "# # Function to clean up all folders in TCGA except for the 'data' folder\n",
    "# def clean_tcga_folder(tcga_folder, data_folder):\n",
    "#     for root, dirs, files in os.walk(baseline_folder, topdown=False):\n",
    "#         for name in dirs:\n",
    "#             folder_path = os.path.join(root, name)\n",
    "#             if folder_path != data_folder:\n",
    "#                 shutil.rmtree(folder_path)\n",
    "#                 print(f\"Deleted folder: {folder_path}\")\n",
    "\n",
    "# # Clean up the folders\n",
    "# clean_tcga_folder(tcga_folder, data_folder)\n",
    "\n",
    "# print(f\"Cleaned up all folders in '{tcga_folder}' except for the 'data' folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1036/1036 [00:41<00:00, 24.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed baseline data saved to 'TCGA/baseline/trimmed_baseline_data.tsv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_folder = os.path.join('TCGA', 'baseline', 'data')\n",
    "output_trimmed_baseline_file = os.path.join('TCGA', 'baseline', 'trimmed_baseline_data.tsv')\n",
    "\n",
    "# Initialize lists to hold the gene IDs and expression data\n",
    "gene_ids = []\n",
    "gene_names = []\n",
    "gene_types = []\n",
    "expression_data = None\n",
    "\n",
    "# Get the list of all .tsv files\n",
    "tsv_files = sorted([f for f in os.listdir(data_folder) if f.endswith('.tsv')])\n",
    "\n",
    "# Iterate through all the TSV files and collect data\n",
    "for i, file_name in enumerate(tqdm(tsv_files, desc=\"Processing files\")):\n",
    "    file_path = os.path.join(data_folder, file_name)\n",
    "    df = pd.read_csv(file_path, sep='\\t', comment='#')\n",
    "    \n",
    "    if i == 0:\n",
    "        gene_ids = df['gene_id'].values\n",
    "        gene_names = df['gene_name'].values\n",
    "        gene_types = df['gene_type'].values\n",
    "        expression_data = np.zeros((len(gene_ids), len(tsv_files)), dtype=np.float32)\n",
    "    \n",
    "    # Use numpy array operations to fill in the data matrix\n",
    "    expression_data[:, i] = df['unstranded'].values\n",
    "\n",
    "# Calculate the trimmed mean across all cases\n",
    "trimmed_mean_expression = np.zeros(len(gene_ids), dtype=np.float32)\n",
    "\n",
    "for j in range(expression_data.shape[0]):\n",
    "    # Sort the values for the gene and trim the top and bottom 1%\n",
    "    sorted_values = np.sort(expression_data[j, :])\n",
    "    trimmed_values = sorted_values[int(0.01 * len(sorted_values)) : int(0.99 * len(sorted_values))]\n",
    "    trimmed_mean_expression[j] = np.mean(trimmed_values)\n",
    "\n",
    "# Calculate the median across all cases (unchanged)\n",
    "median_expression = np.median(expression_data, axis=1)\n",
    "\n",
    "# Create a new DataFrame to hold the trimmed baseline data\n",
    "trimmed_baseline_df = pd.DataFrame({\n",
    "    'gene_id': gene_ids,\n",
    "    'gene_name': gene_names,\n",
    "    'gene_type': gene_types,\n",
    "    'trimmed_mean_expression': trimmed_mean_expression,\n",
    "    'median_expression': median_expression\n",
    "})\n",
    "\n",
    "# Save the trimmed baseline data to a new TSV file\n",
    "trimmed_baseline_df.to_csv(output_trimmed_baseline_file, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Trimmed baseline data saved to '{output_trimmed_baseline_file}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
